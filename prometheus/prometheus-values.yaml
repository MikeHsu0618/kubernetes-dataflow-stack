fullnameOverride: "prometheus-stack"

## https://github.com/prometheus-operator/kube-prometheus/issues/718
## https://github.com/google/cadvisor/issues/3336
#kubeScheduler:
#  enabled: false
#
#kubeControllerManager:
#    enabled: false
#
#kubeEtcd:
#    enabled: false
#
#kubeProxy:
#    enabled: false
#
#kubeApiserver:
#    enabled: false


## Using default values from https://github.com/grafana/helm-charts/blob/main/charts/grafana/values.yaml
##
grafana:
  enabled: true
  ## Deploy default dashboards
  ##
  defaultDashboardsEnabled: true

  persistence:
    accessModes:
      - ReadWriteOnce
    enabled: true
    size: 10Gi
    type: pvc

  ## Timezone for the default dashboards
  ## Other options are: browser or a specific timezone, i.e. Europe/Luxembourg
  ##
######################
  defaultDashboardsTimezone: Asia/Taipei

  adminPassword: admin
######################

######################
  ingress:
    ## If true, Grafana Ingress will be created
    ##
    enabled: true
    ## IngressClassName for Grafana Ingress.
    ## Should be provided if Ingress is enable.
    ##
    ingressClassName: nginx

    hosts: ["grafana.domain.com"]
  ######################

## Configuration for kube-state-metrics subchart
##
kube-state-metrics:
  prometheus:
    monitor:
      enabled: true
  selfMonitor:
    enabled: true


## Deploy node exporter as a daemonset to all nodes
##
######################
nodeExporter:
  enabled: true
  hostRootfs: false
######################

## Configuration for prometheus-node-exporter subchart
##
prometheus-node-exporter:
######################
  hostRootFsMount:
    enabled: false
######################

## Manages Prometheus and Alertmanager components
##
prometheusOperator:
  enabled: true

  ## If true, the operator will create and maintain a service for scraping kubelets
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/helm/prometheus-operator/README.md
  ##
  kubeletService:
    enabled: true

  # Enable vertical pod autoscaler support for prometheus-operator
  verticalPodAutoscaler:
    enabled: false

## Deploy a Prometheus instance
##
prometheus:
  enabled: true

  ingress:
###############
    enabled: true

    # For Kubernetes >= 1.18 you should specify the ingress-controller via the field ingressClassName
    # See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#specifying-the-class-of-an-ingress
    ingressClassName: nginx

    hosts: ["prometheus.domain.com"]

    paths: ["/"]
###############

  serviceMonitor:
    selfMonitor: true


  ## Settings affecting prometheusSpec
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#prometheusspec
  ##
  prometheusSpec:
    enableFeatures: []
    # - exemplar-storage

    ## enable --web.enable-remote-write-receiver flag on prometheus-server
    ##
    enableRemoteWriteReceiver: true

    ## Enable/Disable Grafana dashboards provisioning for prometheus remote write feature
    remoteWriteDashboards: true

    ## How long to retain metrics
    ##
    retention: 10d

    ## Enable compression of the write-ahead log using Snappy.
    ##
    walCompression: true

    ## The remote_read spec configuration for Prometheus.
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#remotereadspec
    remoteRead: []
    # - url: http://remote1/read

    ## The remote_write spec configuration for Prometheus.
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#remotewritespec
    remoteWrite: []
    # - url: http://remote1/push
    ## additionalRemoteWrite is appended to remoteWrite
    additionalRemoteWrite: []


    ## Prometheus StorageSpec for persistent data
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/user-guides/storage.md
    ##
    storageSpec: {}
    ## Using PersistentVolumeClaim
    ##
    #  volumeClaimTemplate:
    #    spec:
    #      storageClassName: gluster
    #      accessModes: ["ReadWriteOnce"]
    #      resources:
    #        requests:
    #          storage: 50Gi

    # Additional volumes on the output StatefulSet definition.
    volumes: []

    # Additional VolumeMounts on the output StatefulSet definition.
    volumeMounts: []

    ## AdditionalScrapeConfigs allows specifying additional Prometheus scrape configurations. Scrape configurations
    ## are appended to the configurations generated by the Prometheus Operator. Job configurations must have the form
    ## as specified in the official Prometheus documentation:
    ## https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config. As scrape configs are
    ## appended, the user is responsible to make sure it is valid. Note that using this feature may expose the possibility
    ## to break upgrades of Prometheus. It is advised to review Prometheus release notes to ensure that no incompatible
    ## scrape configs are going to break Prometheus after the upgrade.
    ## AdditionalScrapeConfigs can be defined as a list or as a templated string.
    ##
    ## The scrape configuration example below will find master nodes, provided they have the name .*mst.*, relabel the
    ## port to 2379 and allow etcd scraping provided it is running on all Kubernetes master nodes
    ##
    additionalScrapeConfigs: []
#      - job_name: 'vector'
#        scrape_interval: 1s
#        static_configs:
#          - targets: [ 'vector.default:9090' ]
#      - job_name: 'promtail'
#        scrape_interval: 1s
#        metrics_path: /metrics
#        static_configs:
#          - targets: [ 'promtail.default:3101' ]